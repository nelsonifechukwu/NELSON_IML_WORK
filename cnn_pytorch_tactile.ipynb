{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset  # Gives easier dataset managment by creating mini batches etc.\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, f1_score, recall_score, precision_score\n",
    "\n",
    "\n",
    "import sys\n",
    "\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read the data \n",
    "#algorithm to read all the files\n",
    "\n",
    "'''\n",
    "for folder in this folder:\n",
    "    read xelasensor1.csv\n",
    "    read sliplabel.csv\n",
    "    concat it in a single dataframe along axis = 0\n",
    "\n",
    "print the dataframe\n",
    "'''\n",
    "\n",
    "directory = '/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/train2dof'\n",
    "directory2 = '/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/'\n",
    "\n",
    "def read_file(detect_or_pred, n = None):\n",
    "\n",
    "    #store all directories in a list\n",
    "    list_xela_allfiles = []\n",
    "    list_sliplabel_allfiles = []\n",
    "\n",
    "    for root, subdirectories, files in os.walk(directory):\n",
    "        for sdirectory in subdirectories:\n",
    "\n",
    "            #subdirectory with absolute path\n",
    "            subdirectory = '{}/{}'.format(root, sdirectory)\n",
    "\n",
    "            #read specific files in the subdirectory\n",
    "            for file in os.listdir(subdirectory):\n",
    "            \n",
    "                if file.endswith(\"sensor1.csv\"):\n",
    "                    df = pd.read_csv('{}/{}'.format(subdirectory, file), index_col=None, header=0)\n",
    "                    \n",
    "                    if detect_or_pred ==0:\n",
    "                        list_xela_allfiles.append(df)\n",
    "                    elif detect_or_pred ==1 and n is not None:\n",
    "                        list_xela_allfiles.append(df[:-n])\n",
    "\n",
    "                if file.endswith(\"label.csv\"):\n",
    "                    df = pd.read_csv('{}/{}'.format(subdirectory, file), index_col=None, header=0)\n",
    "                    if detect_or_pred ==0:\n",
    "                        list_sliplabel_allfiles.append(df)\n",
    "                    elif detect_or_pred ==1 and n is not None: \n",
    "                        list_sliplabel_allfiles.append(df[n:])\n",
    "\n",
    "    return list_xela_allfiles, list_sliplabel_allfiles\n",
    "\n",
    "    #np.newaxis; np.zeros (3,4,4) -> \n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat the list of xela_allfiles and sliplabel_allfiles across axis = 0\n",
    "n = 5\n",
    "list_xela_allfiles, list_sliplabel_allfiles = read_file(0)\n",
    "\n",
    "#for slip prediction, comment the line above and uncomment the line below\n",
    "#list_xela_allfiles, list_sliplabel_allfiles = read_file(1, n)\n",
    "\n",
    "pd_xela_allfiles = pd.concat(list_xela_allfiles, axis=0, ignore_index=True)\n",
    "pd_sliplabel_allfiles = pd.concat(list_sliplabel_allfiles, axis=0, ignore_index=True)\n",
    "pd_sliplabel_allfiles = pd_sliplabel_allfiles['slip']\n",
    "\n",
    "#reshape the target array into (rows, 1)\n",
    "tac_label = pd_sliplabel_allfiles.values.reshape(pd_sliplabel_allfiles.shape[0], 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RE-ARRANGEMENT OF TABULAR DATA INTO IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#arrange the data by 3, 4, 4\n",
    "\n",
    "#arrange the columns by x, y, z\n",
    "col_x = []\n",
    "col_y = []\n",
    "col_z = []\n",
    "\n",
    "pd_columns = pd_xela_allfiles.columns\n",
    "for col in pd_columns:\n",
    "    if col.endswith('x'):\n",
    "        col_x.append(col)\n",
    "    \n",
    "    elif col.endswith('y'):\n",
    "        col_y.append(col)\n",
    "    \n",
    "    elif col.endswith('z'):\n",
    "        col_z.append(col)\n",
    "\n",
    "#arrange the table using the arranged columns\n",
    "pd_xela_allfiles_x = pd_xela_allfiles[col_x]\n",
    "pd_xela_allfiles_y = pd_xela_allfiles[col_y]\n",
    "pd_xela_allfiles_z = pd_xela_allfiles[col_z]\n",
    "\n",
    "\n",
    "#scale the data in the arranged columns\n",
    "#scale the data of the features\n",
    "\n",
    "sc = MinMaxScaler() #standard scaler\n",
    "sc.fit(pd_xela_allfiles_x)\n",
    "pd_xela_allfiles_x = sc.transform(pd_xela_allfiles_x)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_y)\n",
    "pd_xela_allfiles_y = sc.transform(pd_xela_allfiles_y)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_z)\n",
    "pd_xela_allfiles_z = sc.transform(pd_xela_allfiles_z)\n",
    "\n",
    "\n",
    "\n",
    "#reshape the arranged data per row to (4,4) AND rotate 90 degree anti-clockwise and append to a list\n",
    "pd_x = []\n",
    "pd_y = []\n",
    "pd_z = []\n",
    "\n",
    "for row in range(len(pd_xela_allfiles_x)):\n",
    "    pd_x.append(np.rot90(pd_xela_allfiles_x[row].reshape(4,4)))\n",
    "    pd_y.append(np.rot90(pd_xela_allfiles_y[row].reshape(4,4)))\n",
    "    pd_z.append(np.rot90(pd_xela_allfiles_z[row].reshape(4,4)))\n",
    "\n",
    "#add all the x, y, z in a single list\n",
    "pd_main = [pd_x, pd_y, pd_z]\n",
    "\n",
    "#arrange pd_main in a 3, 4, 4 array where its 3(4, 4) of x, y, z values\n",
    "pd_image = np.zeros( (pd_xela_allfiles.shape[0], 3, 4, 4))\n",
    "\n",
    "#per row, get (4,4) of x, y, z and assign it to pd_image to form the image\n",
    "for row in range(pd_xela_allfiles.shape[0]):\n",
    "    x_4_4 = pd_main[0][row]\n",
    "    y_4_4 = pd_main[1][row]\n",
    "    z_4_4 = pd_main[2][row]\n",
    "\n",
    "    pd_image[row][0] = x_4_4\n",
    "    pd_image[row][1] = y_4_4\n",
    "    pd_image[row][2] = z_4_4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR RESNET arrange the columns by x, y, z\n",
    "col_x = []\n",
    "col_y = []\n",
    "col_z = []\n",
    "\n",
    "pd_columns = pd_xela_allfiles.columns\n",
    "for col in pd_columns:\n",
    "    if col.endswith('x'):\n",
    "        col_x.append(col)\n",
    "    \n",
    "    elif col.endswith('y'):\n",
    "        col_y.append(col)\n",
    "    \n",
    "    elif col.endswith('z'):\n",
    "        col_z.append(col)\n",
    "\n",
    "#arrange the table using the arranged columns\n",
    "pd_xela_allfiles_x = pd_xela_allfiles[col_x]\n",
    "pd_xela_allfiles_y = pd_xela_allfiles[col_y]\n",
    "pd_xela_allfiles_z = pd_xela_allfiles[col_z]\n",
    "\n",
    "\n",
    "#scale the data in the arranged columns\n",
    "#scale the data of the features\n",
    "\n",
    "sc = MinMaxScaler() #standard scaler\n",
    "sc.fit(pd_xela_allfiles_x)\n",
    "pd_xela_allfiles_x = sc.transform(pd_xela_allfiles_x)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_y)\n",
    "pd_xela_allfiles_y = sc.transform(pd_xela_allfiles_y)\n",
    "\n",
    "sc.fit(pd_xela_allfiles_z)\n",
    "pd_xela_allfiles_z = sc.transform(pd_xela_allfiles_z)\n",
    "\n",
    "#reshape the arranged data per row to (4,4) AND rotate 90 degree anti-clockwise and append to a list\n",
    "pd_x = []\n",
    "pd_y = []\n",
    "pd_z = []\n",
    "\n",
    "for row in range(len(pd_xela_allfiles_x)):\n",
    "    pd_x.append(np.rot90(pd_xela_allfiles_x[row].reshape(4,4)))\n",
    "    pd_y.append(np.rot90(pd_xela_allfiles_y[row].reshape(4,4)))\n",
    "    pd_z.append(np.rot90(pd_xela_allfiles_z[row].reshape(4,4)))\n",
    "\n",
    "#Upscale each (4, 4) of x, y, z to (224, 224)\n",
    "import cv2\n",
    "up_size = 224\n",
    "n_images = len(pd_x)\n",
    "\n",
    "tac_imagex = np.zeros((n_images, up_size, up_size), np.float32)\n",
    "tac_imagey = np.zeros((n_images, up_size, up_size), np.float32) \n",
    "tac_imagez = np.zeros((n_images, up_size, up_size), np.float32) \n",
    "#resize image to 3, up_size, up_size\n",
    "\n",
    "for row in range(len(pd_x)):\n",
    "    img_4_4_x = pd_x[row]\n",
    "    tac_imagex[row] = cv2.resize(img_4_4_x.astype(np.float32), dsize=(up_size, up_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "for row in range(len(pd_y)):\n",
    "    img_4_4_y = pd_y[row]\n",
    "    tac_imagey[row] = cv2.resize(img_4_4_y.astype(np.float32), dsize=(up_size, up_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "for row in range(len(pd_z)):\n",
    "    img_4_4_z = pd_z[row]\n",
    "    tac_imagez[row] = cv2.resize(img_4_4_z.astype(np.float32), dsize=(up_size, up_size), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "pd_main = [tac_imagex, tac_imagey, tac_imagez]\n",
    "\n",
    "#arrange pd_main in a 3, 224, 224 array where its 3(224, 224) of x, y, z values\n",
    "pd_image = np.zeros( (pd_xela_allfiles.shape[0], 3, up_size, up_size))\n",
    "\n",
    "#per row, get (224,224) of x, y, z and assign it to pd_image to form the image\n",
    "for row in range(pd_xela_allfiles.shape[0]):\n",
    "    x_4_4 = pd_main[0][row]\n",
    "    y_4_4 = pd_main[1][row]\n",
    "    z_4_4 = pd_main[2][row]\n",
    "\n",
    "    pd_image[row][0] = x_4_4\n",
    "    pd_image[row][1] = y_4_4\n",
    "    pd_image[row][2] = z_4_4\n",
    "\n",
    "plt.imshow(tac_imagex[100040])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upscale the image, Train, Get the shape, Form my dense layer\n",
    "\n",
    "#Upscale the (4,4) part of the 3, 4, 4 image to 16, 16, 16,\n",
    "import cv2\n",
    "\n",
    "up_size = 16\n",
    "n_images = len(pd_x)\n",
    "tac_image = np.zeros((n_images, 3, up_size, up_size), np.float32) \n",
    "for row in range(n_images):\n",
    "\n",
    "    #resize image to 3, up_size, up_size\n",
    "    for channel in range(3):\n",
    "        image_per_channel = pd_image[row][channel]\n",
    "        tac_image[row][channel] = cv2.resize(image_per_channel.astype(np.float32), dsize=(up_size, up_size), interpolation=cv2.INTER_CUBIC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show scaled image\n",
    "plt.imshow(tac_image[0][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to tensor values\n",
    "tac_image = torch.from_numpy(tac_image.astype(np.float32))\n",
    "tac_label = torch.from_numpy(tac_label.astype(np.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data into train and test\n",
    "tac_image_train, tac_image_test, tac_label_train, tac_label_test = train_test_split(tac_image, tac_label, test_size=0.1, shuffle=True)\n",
    "\n",
    "#split into train and validation\n",
    "tac_image_train, tac_image_valid, tac_label_train, tac_label_valid = train_test_split(tac_image_train, tac_label_train, test_size=0.3, shuffle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Batch training for the data\n",
    "\n",
    "class Batch_Taxels(Dataset):\n",
    "\n",
    "    def __init__(self, tac_image_train, tac_label_train, tac_image_valid, tac_label_valid, valid = None):\n",
    "        self.x = tac_image_train\n",
    "        self.y = tac_label_train\n",
    "        self.xvalid = tac_image_valid\n",
    "        self.yvalid = tac_label_valid\n",
    "        self.valid = valid\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.valid == True:\n",
    "            return self.xvalid.shape[0]\n",
    "        else:\n",
    "            return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if self.valid == True:\n",
    "            return self.xvalid[idx], self.yvalid[idx]\n",
    "        else:\n",
    "            return self.x[idx], self.y[idx]\n",
    "\n",
    "#Divide the data into batches\n",
    "dataset = Batch_Taxels(tac_image_train, tac_label_train, tac_image_valid, tac_label_valid)\n",
    "dataset2 = Batch_Taxels(tac_image_train, tac_label_train, tac_image_valid, tac_label_valid, valid = True)\n",
    "\n",
    "xelaloader = DataLoader(dataset = dataset, batch_size=32, shuffle=True)\n",
    "xelaloadervalid = DataLoader(dataset = dataset2, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_channels=3, num_classes=1):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=16,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            in_channels=16,\n",
    "            out_channels=64,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            in_channels=64,\n",
    "            out_channels=128,\n",
    "            kernel_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            padding=(1, 1),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        #print(x.shape) \n",
    "    \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x)) #apply droupout in the layer\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "       \n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and validation loop \n",
    "\n",
    "num_epochs = 10\n",
    "learning_rate  = 0.0001\n",
    "model = CNN()\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = nn.BCELoss()#pos_weight=torch.tensor([2.0]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "\n",
    "t_acc = []\n",
    "v_acc = []\n",
    "\n",
    "t_acc_t = []\n",
    "v_acc_t = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #Train per batch\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    l_xelaloader = 0\n",
    "\n",
    "    model.train()\n",
    "    for (x, y) in (xelaloader):\n",
    "\n",
    "        #Forward pass\n",
    "        y_pred = model(x)\n",
    "       \n",
    "        #compute the loss\n",
    "        l = loss(y_pred, y)\n",
    "\n",
    "        #empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #compute the gradient\n",
    "        l.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        #append each loss per batch\n",
    "        train_loss.append(l.item())\n",
    "\n",
    "        #accuracy\n",
    "        total += y.size(0)\n",
    "        correct += y_pred.round().eq(y).sum().item()\n",
    "        l_xelaloader += x.shape[0]\n",
    "        \n",
    "    \n",
    "    t_acc = correct/l_xelaloader\n",
    "    t_acc_t.append(t_acc)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    l_xelaloader = 0\n",
    "\n",
    "    #calculate and plot the validation loss\n",
    "    model.eval()\n",
    "    for (x,y) in (xelaloadervalid):\n",
    "        y_pred_test = model(x)\n",
    "        lv = loss(y_pred_test, y)\n",
    "        #append the loss per batch\n",
    "        valid_loss.append(lv.item())\n",
    "\n",
    "        #accuracy\n",
    "        total += y.size(0)\n",
    "        correct += y_pred_test.round().eq(y).sum().item()\n",
    "        l_xelaloader += x.shape[0]\n",
    "        \n",
    "    v_acc = correct/l_xelaloader\n",
    "    v_acc_t.append(v_acc)\n",
    "\n",
    "    #append the total loss and accuracy per epoch\n",
    "    t_loss.append(np.mean(train_loss))\n",
    "    v_loss.append(np.mean(valid_loss))\n",
    "\n",
    "    print(f'For training epoch {epoch+1}, loss ={l:.8f}', f'For validation epoch {epoch+1}, loss ={lv:.8f}'  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the loss per epoch for training and validation for CNN\n",
    "\n",
    "fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "\n",
    "#set labels\n",
    "ax[0].set_xlabel('Epochs', color = 'black')\n",
    "ax[0].set_ylabel('Loss', color = 'black')\n",
    "ax[1].set_xlabel('Epochs', color = 'black')\n",
    "ax[1].set_ylabel('Accuracy', color = 'black')\n",
    "\n",
    "\n",
    "ax[0].plot(t_loss, label='Train Loss', color='red', linewidth=2, linestyle='dashed')\n",
    "ax[0].plot(v_loss, label='Validation Loss', color = 'blue')\n",
    "ax[1].plot(t_acc_t, label = 'Train Accuracy', color = 'orange')\n",
    "ax[1].plot(v_acc_t, label = 'Validation Accuracy', color = 'green')\n",
    "\n",
    "#set legends\n",
    "ax[0].legend()\n",
    "ax[1].legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics definition\n",
    "def detection_metrics(xela_test, sliplabel_test, model_type):\n",
    "    #predict using the holdout set (DONE)\n",
    "    predicted = model_type(xela_test).detach()#.numpy()\n",
    "    _, predicted_cls = predicted.max(1)\n",
    "    predicted_cls = predicted_cls.numpy().round()\n",
    "\n",
    "    #Plot the loss values against number of epochs (DONE)\n",
    "    #validation test (DONE)\n",
    "\n",
    "    #Print the accuracy\n",
    "    x = 0\n",
    "    for i in range(predicted_cls.shape[0]):\n",
    "        if predicted_cls[i].item() == sliplabel_test[i].item():\n",
    "            x += 1\n",
    "\n",
    "    accuracy = x/ float(sliplabel_test.shape[0])\n",
    "    print(f'Accuracy for slip detection is {accuracy}')\n",
    "\n",
    "    #Print the fscore\n",
    "    fscore = f1_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Fscore for slip detection is {fscore}')\n",
    "\n",
    "    #print the Precision\n",
    "    precision = precision_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Precision for slip detection is {precision}')\n",
    "\n",
    "    #print the Recall\n",
    "    recall = recall_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Recall for slip detection is {recall}')\n",
    "\n",
    "def slip_metrics(xela_test, sliplabel_test, modeltype):\n",
    "    #predict using the holdout set (DONE)\n",
    "    predicted = modeltype(xela_test).detach()#.numpy()\n",
    "    _, predicted_cls = predicted.max(1)\n",
    "    predicted_cls = predicted_cls.numpy().round()\n",
    "    \n",
    "    #Plot the loss values against number of epochs (DONE)\n",
    "    #validation test (DONE)\n",
    "\n",
    "    #Print the accuracy\n",
    "    x = 0\n",
    "    for i in range(predicted_cls.shape[0]):\n",
    "        if predicted_cls[i].item() == sliplabel_test[i].item():\n",
    "            x += 1\n",
    "\n",
    "    accuracy = x/ float(sliplabel_test.shape[0])\n",
    "    print(f'Accuracy for slip prediction for (t+{n}) is {accuracy}')\n",
    "\n",
    "    #Print the fscore\n",
    "    fscore = f1_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Fscore for slip prediction for (t+{n}) is {fscore}')\n",
    "\n",
    "    #print the Precision\n",
    "    precision = precision_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Precision for slip prediction for (t+{n}) is {precision}')\n",
    "\n",
    "    #print the Recall\n",
    "    recall = recall_score(sliplabel_test.numpy(), predicted_cls, average='macro')\n",
    "    print(f'Recall for slip prediction for (t+{n}) is {recall}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print metrics\n",
    "detection_metrics(tac_image_test, tac_label_test, model)\n",
    "slip_metrics(tac_image_test, tac_label_test, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RESNET IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upscale from 4,4 to 224, 244, then, reshae x, y, z to 3, 224, 224\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tac_image.shape, tac_label.shape, tac_image_train.shape, tac_label_train.shape, tac_image_valid.shape, tac_label_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(tac_image_train[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the batch training class for the model\n",
    "mean = np.array([0.5, 0.5, 0.5])\n",
    "std = np.array([0.25, 0.25, 0.25])\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "composed = torchvision.transforms.Compose ([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean, std)])\n",
    "\n",
    "class tactile_resnet(Dataset):\n",
    "    def __init__(self, tac_image, tac_label, transform = None):\n",
    "        self.x = tac_image\n",
    "        self.y = tac_label\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        sample = self.x[index], self.y[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "data_set_train = tactile_resnet(tac_image_train, tac_label_train, transform = None)\n",
    "data_set_valid = tactile_resnet(tac_image_valid, tac_label_valid, transform = None)\n",
    "\n",
    "dataloader_train = DataLoader(dataset = data_set_train, batch_size = 32, shuffle = True )\n",
    "dataloader_valid = DataLoader(dataset = data_set_valid, batch_size = 32, shuffle = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "\n",
    "    t_loss = []\n",
    "    v_loss = []\n",
    "\n",
    "    t_acc = []\n",
    "    v_acc = []\n",
    "\n",
    "    t_acc_t = []\n",
    "    v_acc_t = []\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        l_xelaloader = 0\n",
    "\n",
    "        #Training\n",
    "        for inputs, labels in dataloader_train:\n",
    "            model.train()\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            #empty the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            t = time.time()\n",
    "            #Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            print(time.time() - t)\n",
    "            #compute the loss\n",
    "            l = criterion(outputs, labels)\n",
    "\n",
    "            #apply softmax to the output\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            #compute the gradient\n",
    "            l.backward()\n",
    "\n",
    "            #update the weights\n",
    "            optimizer.step()\n",
    "\n",
    "            scheduler.step()\n",
    "            #append each loss per batch\n",
    "            train_loss.append(l.item())\n",
    "\n",
    "            #accuracy\n",
    "            total += labels.size(0)\n",
    "            correct += outputs.round().eq(labels).sum().item()\n",
    "            l_xelaloader += inputs.shape[0]\n",
    "        \n",
    "    \n",
    "        t_acc = correct/l_xelaloader\n",
    "        t_acc_t.append(t_acc)\n",
    "\n",
    "        total = 0\n",
    "        correct = 0\n",
    "        l_xelaloader = 0\n",
    "        \n",
    "        #append the total training loss and accuracy per epoch\n",
    "        t_loss.append(np.mean(train_loss))\n",
    "\n",
    "        #validation\n",
    "        model.eval()\n",
    "        for inputs, labels in dataloader_valid:\n",
    "            outputs_valid = model(inputs)\n",
    "            lv = criterion(outputs_valid, labels)\n",
    "\n",
    "            _, preds = torch.max(outputs_valid, 1)\n",
    "\n",
    "                #append each loss per batch\n",
    "            valid_loss.append(lv.item())\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += outputs.round().eq(labels).sum().item()\n",
    "            l_xelaloader += inputs.shape[0]\n",
    "    \n",
    "        v_acc = correct/l_xelaloader\n",
    "        v_acc_t.append(v_acc)\n",
    "            # deep copy the model\n",
    "        if t_acc > best_acc:\n",
    "            best_acc = t_acc\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        #Metrics\n",
    "        #append the total validation loss and accuracy per epoch\n",
    "        v_loss.append(np.mean(valid_loss))\n",
    "\n",
    "        \n",
    "    print(f'For training epoch {epoch+1}, loss ={l:.8f}', f'For validation epoch {epoch+1}, loss ={lv:.8f}'  )\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pretrained model and reset final fully connected layer.\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_ftrs = model.fc.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "\n",
    "#create the new fully connected layer of the model\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "#print(model)\n",
    "\n",
    "# StepLR Decays the learning rate of each parameter group by gamma every step_size epochs\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "# Learning rate scheduling should be applied after optimizerâ€™s update\n",
    "# e.g., you should write your code this way:\n",
    "# for epoch in range(100):\n",
    "#     train(...)\n",
    "#     validate(...)\n",
    "#     scheduler.step()\n",
    "\n",
    "step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ConvNet as fixed feature extractor ####\n",
    "# Here, we need to freeze all the network except the final layer.\n",
    "# We need to set requires_grad == False to freeze the parameters so that the gradients are not computed in backward()\n",
    "model_conv = models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Parameters of newly constructed modules have requires_grad=True by default\n",
    "num_ftrs = model_conv.fc.in_features\n",
    "\n",
    "model_conv.fc = nn.Linear(num_ftrs, 1)\n",
    "\n",
    "model_conv = model_conv.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that only parameters of final layer are being optimized as\n",
    "# opposed to before.\n",
    "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=7, gamma=0.1)\n",
    "\n",
    "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN & LSTM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 16, 16]) torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "for x, y in xelaloader:\n",
    "    print (x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsize = 2 # 2 => 16*16 as 2D\n",
    "seq_length = 3 # 3 => unroll for x, y, z\n",
    "num_layers = 2 \n",
    "hidden_size = 2\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, inputsize, hidden_size, num_layers, num_classes = 1):\n",
    "        super (RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.RNN(inputsize, hidden_size, num_layers, batch_first = True)\n",
    "\n",
    "        self.fc  = nn.Linear(hidden_size*seq_length, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(num_layers, x.shape[0], inputsize)\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "empty(): argument 'size' must be tuple of ints, but found element of type RNN at pos 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb Cell 30\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m#Training and validation loop \u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m RNN(inputsize, hidden_size, num_layers, num_classes \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# Loss and optimizer\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m loss \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mBCELoss()\u001b[39m#pos_weight=torch.tensor([2.0]))\u001b[39;00m\n",
      "\u001b[1;32m/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb Cell 30\u001b[0m in \u001b[0;36mRNN.__init__\u001b[0;34m(self, inputsize, hidden_size, num_layers, num_classes)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhidden_size \u001b[39m=\u001b[39m hidden_size\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers \u001b[39m=\u001b[39m num_layers\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrnn \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mRNN(\u001b[39mself\u001b[39;49m, inputsize, hidden_size, num_layers, batch_first \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/elijahnelson/Desktop/SIWES/IML/Tactile_IML/cnn_pytorch_tactile.ipynb#X41sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc  \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mLinear(hidden_size\u001b[39m*\u001b[39mseq_length, num_classes)\n",
      "File \u001b[0;32m~/miniforge3/envs/nei/lib/python3.8/site-packages/torch/nn/modules/rnn.py:420\u001b[0m, in \u001b[0;36mRNN.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    419\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnknown nonlinearity \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnonlinearity))\n\u001b[0;32m--> 420\u001b[0m \u001b[39msuper\u001b[39;49m(RNN, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(mode, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/nei/lib/python3.8/site-packages/torch/nn/modules/rnn.py:89\u001b[0m, in \u001b[0;36mRNNBase.__init__\u001b[0;34m(self, mode, input_size, hidden_size, num_layers, bias, batch_first, dropout, bidirectional, proj_size, device, dtype)\u001b[0m\n\u001b[1;32m     86\u001b[0m real_hidden_size \u001b[39m=\u001b[39m proj_size \u001b[39mif\u001b[39;00m proj_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m hidden_size\n\u001b[1;32m     87\u001b[0m layer_input_size \u001b[39m=\u001b[39m input_size \u001b[39mif\u001b[39;00m layer \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m real_hidden_size \u001b[39m*\u001b[39m num_directions\n\u001b[0;32m---> 89\u001b[0m w_ih \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39;49mempty((gate_size, layer_input_size), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfactory_kwargs))\n\u001b[1;32m     90\u001b[0m w_hh \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty((gate_size, real_hidden_size), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n\u001b[1;32m     91\u001b[0m b_ih \u001b[39m=\u001b[39m Parameter(torch\u001b[39m.\u001b[39mempty(gate_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfactory_kwargs))\n",
      "\u001b[0;31mTypeError\u001b[0m: empty(): argument 'size' must be tuple of ints, but found element of type RNN at pos 2"
     ]
    }
   ],
   "source": [
    "#Training and validation loop \n",
    "model = RNN(inputsize, hidden_size, num_layers, num_classes = 1)\n",
    "\n",
    "# Loss and optimizer\n",
    "loss = nn.BCELoss()#pos_weight=torch.tensor([2.0]))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "train_loss = []\n",
    "valid_loss = []\n",
    "\n",
    "t_loss = []\n",
    "v_loss = []\n",
    "\n",
    "t_acc = []\n",
    "v_acc = []\n",
    "\n",
    "t_acc_t = []\n",
    "v_acc_t = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    #Train per batch\n",
    "    \n",
    "    total = 0\n",
    "    correct = 0\n",
    "    l_xelaloader = 0\n",
    "\n",
    "    model.train()\n",
    "    for (x, y) in (xelaloader):\n",
    "\n",
    "        #Forward pass\n",
    "        y_pred = model(x)\n",
    "       \n",
    "        #compute the loss\n",
    "        l = loss(y_pred, y)\n",
    "\n",
    "        #empty the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #compute the gradient\n",
    "        l.backward()\n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        #append each loss per batch\n",
    "        train_loss.append(l.item())\n",
    "\n",
    "        #accuracy\n",
    "        total += y.size(0)\n",
    "        correct += y_pred.round().eq(y).sum().item()\n",
    "        l_xelaloader += x.shape[0]\n",
    "        \n",
    "    \n",
    "    t_acc = correct/l_xelaloader\n",
    "    t_acc_t.append(t_acc)\n",
    "\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    l_xelaloader = 0\n",
    "\n",
    "    #calculate and plot the validation loss\n",
    "    model.eval()\n",
    "    for (x,y) in (xelaloadervalid):\n",
    "        y_pred_test = model(x)\n",
    "        lv = loss(y_pred_test, y)\n",
    "        #append the loss per batch\n",
    "        valid_loss.append(lv.item())\n",
    "\n",
    "        #accuracy\n",
    "        total += y.size(0)\n",
    "        correct += y_pred_test.round().eq(y).sum().item()\n",
    "        l_xelaloader += x.shape[0]\n",
    "        \n",
    "    v_acc = correct/l_xelaloader\n",
    "    v_acc_t.append(v_acc)\n",
    "\n",
    "    #append the total loss and accuracy per epoch\n",
    "    t_loss.append(np.mean(train_loss))\n",
    "    v_loss.append(np.mean(valid_loss))\n",
    "\n",
    "    print(f'For training epoch {epoch+1}, loss ={l:.8f}', f'For validation epoch {epoch+1}, loss ={lv:.8f}'  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('nei')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 | packaged by conda-forge | (default, Mar 25 2022, 06:04:14) \n[Clang 12.0.1 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "173c0cb41f479ae2d1f90bf66f9ae3aceca0c8feada6413b4ebace4131a19a6b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
